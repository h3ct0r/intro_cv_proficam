{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aula_06_05_FRCNN","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNUyrrULpt9LbkUb8cGu2VA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8_12Y4_jvE5u"},"source":["# **Instituto Tecnológico Vale**\n","\n","## **Introdução a Visão Computacional**\n","\n","### **Aula 06 - Detecção de objetos com Faster RCNN**"]},{"cell_type":"code","metadata":{"id":"aclI8ttjqHSp"},"source":["!wget -O coco_classes.pickle https://www.dropbox.com/s/zfrbfi9o10wplvf/coco_classes.pickle?dl=0\n","\n","!wget -O transito.jpg https://www.dropbox.com/s/r9hg5mt2fllcoz3/transito.jpg?dl=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fP3VBq75pXLQ"},"source":["# import the necessary packages\n","\n","from torchvision.models import detection\n","import numpy as np\n","import argparse\n","import pickle\n","import torch\n","import cv2\n","\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TEWd21ypYi_"},"source":["# define o dispositivo que usaremos para executar o modelo\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gPo81ZnpfKD"},"source":["# carregua a lista de categorias no conjunto de dados COCO e, \n","# em seguida, gere um conjunto de cores da caixa delimitadora para cada classe\n","\n","CLASSES = pickle.loads(open(\"/content/coco_classes.pickle\", \"rb\").read())\n","\n","COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WeFVw6Z3tl9O"},"source":["# Defina uma threshold para a confiança da detecção\n","\n","cf_thresh = 0.7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAj4eVIYqR_X"},"source":["# inicializa um dicionário contendo o nome do modelo e sua chamada de função torchvision correspondente\n","\n","MODELS = {\n","\t\"frcnn-resnet\": detection.fasterrcnn_resnet50_fpn,\n","\t\"frcnn-mobilenet\": detection.fasterrcnn_mobilenet_v3_large_320_fpn,\n","\t\"retinanet\": detection.retinanet_resnet50_fpn\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rAF19o7qfbD"},"source":["# carregua o modelo e configure-o para o modo de avaliação\n","\n","# DIgite aqui o nome da rede que você quer usar. Escolha uma das três indicadas em MODELS\n","key = 'frcnn-resnet'\n","\n","model = MODELS[key](pretrained=True, progress=True,\n","                    num_classes=len(CLASSES),\n","                    pretrained_backbone=True).to(DEVICE)\n","\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1B6v2by4rAki"},"source":["# carregua a imagem do disco\n","\n","# Escolha a sua imagem!\n","\n","image = cv2.imread('/content/transito.jpg')\n","orig = image.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTqQm8HSse7d"},"source":["#converter a imagem de BGR para a ordem de canal RGB e \n","# mudar a ordem dos canais para o formtao que pytorch aceita [c, w, h]\n","\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image = image.transpose((2, 0, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSzaaJm8s3XJ"},"source":["# Adiciona a dimensão do lote, \n","# dimensiona as intensidades de pixel bruto para o intervalo [0, 1] \n","# e converte a imagem em um tensor de ponto flutuante\n","\n","image = np.expand_dims(image, axis=0)\n","image = image / 255.0\n","image = torch.FloatTensor(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lakm4JnxtKmp"},"source":["# envia a imahgem para o dispositivo da (GPU) e passa pela rede para obter as detecções e previsões\n","\n","image = image.to(DEVICE)\n","detections = model(image)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mvPmvL9tXZH"},"source":["# loop over the detections\n","for i in range(0, len(detections[\"boxes\"])):\n","\t# extract the confidence (i.e., probability) associated with the\n","\t# prediction\n","\tconfidence = detections[\"scores\"][i]\n","\n","\t# filter out weak detections by ensuring the confidence is\n","\t# greater than the minimum confidence\n","\tif confidence > cf_thresh:\n","\t\t# extract the index of the class label from the detections,\n","\t\t# then compute the (x, y)-coordinates of the bounding box\n","\t\t# for the object\n","\t\tidx = int(detections[\"labels\"][i])\n","\t\tbox = detections[\"boxes\"][i].detach().cpu().numpy()\n","\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n","\n","\t\t# display the prediction to our terminal\n","\t\tlabel = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n","\t\tprint(\"[INFO] {}\".format(label))\n","\n","\t\t# draw the bounding box and label on the image\n","\t\tcv2.rectangle(orig, (startX, startY), (endX, endY),\n","\t\t\tCOLORS[idx], 2)\n","\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n","\t\tcv2.putText(orig, label, (startX, y),\n","\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScWFS034t4yo"},"source":["# Mostra a imagem com as detecções\n","\n","cv2_imshow(orig)\n","cv2.waitKey(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cv1wIoLIuFsz"},"source":[""],"execution_count":null,"outputs":[]}]}