{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aula_05_04_CNN_pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhe3FuJ9ppAwKbr967MXKx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"U1SuGMQrhuoi"},"source":["# **Instituto Tecnológico Vale**\n","\n","## **Introdução a Visão Computacional**\n","\n","### **Reconhecimento de imagem**"]},{"cell_type":"markdown","metadata":{"id":"8DysQztpSn6a"},"source":["## **Exemplo prático**\n","\n","### Construção e treinamento de CNN para classificação de imagens"]},{"cell_type":"code","metadata":{"id":"Ohz3czCEhuGk"},"source":["# baixar e descompactar os dados do exemplo\n","# Será criado a pasta hymenoptera_data no ambiente do colab\n","\n","!wget -O hymenoptera_data.zip https://www.dropbox.com/s/154i61alh62e7jl/hymenoptera_data.zip?dl=0;\n","\n","!unzip hymenoptera_data.zip;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU9yXx0wjNt5"},"source":["#imports necessários\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIoL9VD8jOFK"},"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    \n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6xeKuZTjVTZ"},"source":["# Criando os datasets e dataloaders\n","\n","# Aqui usamos a função ImageFolder para criar um dataset deireto das pastas organizadas train e val.\n","# O pytorch entende automaticamente os nomes das pastas ants e bees como as classes.\n","\n","data_dir = 'hymenoptera_data'\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n","                                             shuffle=True, num_workers=0)\n","              for x in ['train', 'val']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(f'Dataset sizes: {dataset_sizes}')\n","print(f'class names: {class_names}')\n","print(f'cuda: {device}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXhzXmvNjk_p"},"source":["# Funções auxiliares para a prática\n","\n","# Função auxiliar para impimir um batch de imagens\n","\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","\n","    #plt.figure(figsize=(10, 8))\n","\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","\n","# Function to test output dimension\n","def out_conv2d(dim_input, kernel_size, padding=0, dilation=1, stride=1):\n","    dim_output = ((dim_input + 2 * padding - dilation * (kernel_size-1) - 1)/stride) + 1\n","    return dim_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBc4D36avZ19"},"source":["# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fI96qKoqjqnZ"},"source":["# função de treino\n","\n","def train_model(model, criterion, optimizer, num_epochs=15):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEvaqHGtnyBv"},"source":["# Função a ser chamada após treino para visualizar a classificação de um batch\n","\n","def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AddtZjenrm6I"},"source":["# testando as saidas da camadas conv2d\n","# Use esta opção para clacular corretamente as dimensões\n","\n","# Insira a dimensão de entrada e o tamanho do filtro\n","out_conv2d(111, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2IF2WSWn1AK"},"source":["# Criando uma rede convolucional\n","\n","class classificador(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    # Criação das camadas convolucionais\n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3)) # saida 222x222 (no pooling cai pela metade -> 111)\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3)) #saida 109x109 (no pooling cai pela metade -> 54)\n","\n","    # Criação da função relu\n","    self.activation = nn.ReLU()\n","\n","    # Criação do pooling\n","    self.pool = nn.MaxPool2d(kernel_size = (2,2))\n","\n","    # Criação do flatten para vetorzar a imagem ao final das camadas conv\n","    self.flatten = nn.Flatten() # 54*54 * 128 channels\n","\n","    # Camadas lineares da rede neural\n","    self.linear1 = nn.Linear(in_features=128 * 54*54, out_features=128)\n","    self.linear2 = nn.Linear(128, 64)\n","    self.output = nn.Linear(64, 2)\n","\n","    # Dropout para diminuir overfitting\n","    self.dropout = nn.Dropout(p = 0.2)\n","\n","  # Fluxo da passagem da imagem na rede \n","  def forward(self, X):\n","    X = self.pool(self.activation(self.conv1(X)))\n","    X = self.pool(self.activation(self.conv2(X)))\n","    \n","    X = self.flatten(X)\n","\n","    X = self.dropout(self.activation(self.linear1(X)))\n","    X = self.dropout(self.activation(self.linear2(X)))\n","    X = self.output(X)\n","\n","    return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pT1L8SaoT9Z"},"source":["# Criando objeto da estrutura da rede\n","\n","net = classificador()\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-yF5bawoUUJ"},"source":["# Definindo parâmetros importantes do treinamento\n","\n","#Função de custo e função de otimização dos parâmetros\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MylSH-YkoWSp"},"source":["# Colocar a rede na gpu\n","net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EsP1K6sOoZh7"},"source":["# treinar modelo\n","trained_model = train_model(net, criterion, optimizer, num_epochs=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYSa2QuZpKD6"},"source":["# Visualizar imagens do conjunto de teste classificadas\n","visualize_model(trained_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M62x18Bss6SM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0AaYHcEwxAs"},"source":["### Redes Neurais convolucionais pré treinadas e Transfer Learning\n","\n","Existem modelos pre treinados disponiveis no modulo models do pytorch.\n","\n","Estas redes foram treinadas e validadas em competições e são capzaes de classificar várias coisas: 1000 classes.\n","\n","Podemos usar estas redes como base para nossos problemas e retreiná-las com nossos dados.\n","\n"]},{"cell_type":"code","metadata":{"id":"zhYx3tPFwYSg"},"source":["# Carregando do pytorch a rede chamada vgg16\n","model_ft = models.vgg16(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpzh5tFqw6zL"},"source":["print(model_ft)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSc8AqRyxSL7"},"source":["# Parameters of newly constructed modules have requires_grad=True by default\n","num_ftrs = model_ft.classifier[6].in_features\n","\n","# Here the size of each output sample is set to 2.\n","# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n","model_ft.classifier[6] = nn.Linear(num_ftrs, 2)\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Is4TTxpTyhN2"},"source":["print(model_ft)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1et1UogyG2x"},"source":["# treinar modelo\n","trained_model = train_model(model_ft, criterion, optimizer_ft, num_epochs=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ul3q4i8MyNMr"},"source":[""],"execution_count":null,"outputs":[]}]}