{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aula_05_homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53PAiYhZ0pAe"
      },
      "source": [
        "# **Instituto Tecnológico Vale**\n",
        "\n",
        "## **Introdução a Visão Computacional**\n",
        "\n",
        "### **Aula 05 - Reconhecimento de imagem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rxfda00zka"
      },
      "source": [
        "## **Exercício 1**\n",
        "\n",
        "### Atualize o exemplo prático de reconhcimento de logos para reconhecer o logo da Vale.\n",
        "\n",
        "- Crie as novas pastas nos locais corretos e insira as novas imagens do logo Vale.\n",
        "\n",
        "- Execute o treinamento conforme a prática\n",
        "\n",
        "- Na fase da previsão de teste, se a previsão for do logo Vale escreva o nome da em verde, caso contrário escreva o nome da marca em amarelo.\n",
        "\n",
        "\n",
        "### **Enviar até o dia 03/09 por email**\n",
        "\n",
        "**- Código está disponível abaixo abaixo. Edite onde for indicado.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTvVTp-c5AkE"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdeAHSVY5GP7"
      },
      "source": [
        "# Baixar os arquivos necessários para a aula\n",
        "!rm -rf intro_cv_proficam\n",
        "!git clone https://github.com/h3ct0r/intro_cv_proficam\n",
        "!cp -r intro_cv_proficam/img img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2tmFgVf5Gu_"
      },
      "source": [
        "### Colocar o seu codigo aqui!!!\n",
        "\n",
        "# Crie as variaveis para os dados e labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sbvzpaT5dSk"
      },
      "source": [
        "# Loop pelas imagens no dataset de treino\n",
        "\n",
        "for imagePath in paths.list_images(\"img/pratica_logos/logos\"):\n",
        "\tmake = imagePath.split(\"/\")[-2]\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\tedged = imutils.auto_canny(gray)\n",
        "\n",
        "\t# Encontra contornos no mapa de borda, mantendo apenas o maior que se supõe ser o logotipo do carro\n",
        "\t(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t# Extrai o logotipo do carro e redimensiona \n",
        "\t(x, y, w, h) = cv2.boundingRect(c)\n",
        "\tlogo = gray[y:y + h, x:x + w]\n",
        "\tlogo = cv2.resize(logo, (200, 100))\n",
        "\n",
        "\t### Colocar o seu codigo aqui!!!\n",
        "  # execute o algoritmo hog para extração das features\n",
        "\n",
        "\t# Atualiza dados e labels\n",
        "\tdata.append(H)\n",
        "\tlabels.append(make)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm4jx2il5vEQ"
      },
      "source": [
        "### Colocar o seu codigo aqui!!!\n",
        "\n",
        "# Crie o modelo do KNeighborsClassifier e treine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH2y8Qki56Dj"
      },
      "source": [
        "# Loop no dataset de teste\n",
        "print (\"Avaliando...\")\n",
        "for (i, imagePath) in enumerate(paths.list_images(\"img/pratica_logos/test_images\")):\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\tlogo = cv2.resize(gray, (200, 100))\n",
        "\n",
        "\t# Extrai o Histograma de Gradientes Orientados da imagem de teste e prevê a marca do carro\n",
        "\tH = feature.hog(logo, orientations=9, pixels_per_cell=(10, 10), cells_per_block=(2, 2), transform_sqrt=True)\n",
        "\tpred = model.predict(H.reshape(1, -1))[0]\n",
        "\n",
        "\t### Colocar o seu codigo aqui!!!\n",
        "  faça o print correto das previsões considerando a cor do texto sugerida para o exercício"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP26FSTu6PPz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypkpP1rK6PEh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs_IMGIb6O92"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L0d-f5H02UL"
      },
      "source": [
        "## **Exercício 2**\n",
        "\n",
        "### Construa sua rede convolucional para classificação das imagens de ants e bees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmshlw2-8sjC"
      },
      "source": [
        "- Não use o mesmo modelo criado em aula.\n",
        "\n",
        "- Teste os hiperparâmetros para melhorar seu resultado.\n",
        "\n",
        "- Descreva a estrutura final da sua rede.\n",
        "\n",
        "- Utilize as células do colab para descrever como foi o processo de treino e quais mudanças tiveram mais efeito nos resultados.\n",
        "\n",
        "- Comente sobre as dificuldades encontradas e o que pode ser feito para melhorar os resultados.\n",
        "\n",
        "**- Código está disponível abaixo abaixo. Edite onde for indicado.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWkNVHIg8tGv"
      },
      "source": [
        "# baixar e descompactar os dados do exemplo\n",
        "# Será criado a pasta hymenoptera_data no ambiente do colab\n",
        "\n",
        "!wget -O hymenoptera_data.zip https://www.dropbox.com/s/154i61alh62e7jl/hymenoptera_data.zip?dl=0;\n",
        "\n",
        "!unzip hymenoptera_data.zip;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caGErSZ_-Gu1"
      },
      "source": [
        "#imports necessários\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tU4UNY0-KHH"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "# Dica: veja sugestões de mais transformações para data augmentation em https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "                                 # Coloque o seu data augmentation aqui!!!\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f64cD3uu-V9R"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "\n",
        "# Crie os datasets e dataloaders específicos\n",
        "\n",
        "data_dir = 'hymenoptera_data'\n",
        "\n",
        "\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f'Dataset sizes: {dataset_sizes}')\n",
        "print(f'class names: {class_names}')\n",
        "print(f'cuda: {device}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvgS2-lU-cGG"
      },
      "source": [
        "# Funções auxiliares para a prática\n",
        "\n",
        "# Função auxiliar para impimir um batch de imagens\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    #plt.figure(figsize=(10, 8))\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrwvPq_f-fSx"
      },
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvNGsp_s-irO"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "# função de treino\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=15):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ###Colocar o seu codigo aqui!!!\n",
        "                    # Passe a imagem pela rede e calcule o erro\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        ###Colocar o seu codigo aqui!!!\n",
        "                        # atualize os pesos\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfRCynOW_DcK"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFtL9fR8_GWJ"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "# Crie a sua CNN\n",
        "\n",
        "class classificador(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Coloque seu código aqui\n",
        "\n",
        "\n",
        "  # Fluxo da passagem da imagem na rede \n",
        "  def forward(self, X):\n",
        "\n",
        "    # Coloque seu código aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGjzcyEi_Tu8"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "# Crie o objeto do classificador\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUlQKCRh_V9_"
      },
      "source": [
        "###Colocar o seu codigo aqui!!!\n",
        "\n",
        "# Defina sua loss function e o otimizador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPIzitX2_mSE"
      },
      "source": [
        "###Colocar o seu codigo aqui!!!\n",
        "\n",
        "# Coloque a rede na gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORFBhLIY_qcr"
      },
      "source": [
        "### Atenção célula editável!!!\n",
        "\n",
        "# Define a quantidade de epocas e treine o modelo\n",
        "\n",
        "trained_model = train_model(net, criterion, optimizer, num_epochs=)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJ4Cs1S_yMV"
      },
      "source": [
        "# Visualizar imagens do conjunto de teste classificadas\n",
        "visualize_model(trained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5ziEy3s_zZM"
      },
      "source": [
        "### Descreva seus resultados e faça os comentários abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NENS73a_1o2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}